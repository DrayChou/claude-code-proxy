#!/usr/bin/env python3
"""
æµ‹è¯•tokenå‹ç¼©ç­–ç•¥çš„è„šæœ¬
"""
import sys
import os
import logging
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from src.core.token_manager import TokenManager
# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
def create_test_messages():
    """åˆ›å»ºæµ‹è¯•æ¶ˆæ¯åˆ—è¡¨"""
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
        {"role": "user", "content": "è¯·å¸®æˆ‘å†™ä¸€ä¸ªPythonå‡½æ•°æ¥è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—ã€‚" * 20},
        {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ å†™ä¸€ä¸ªæ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°ã€‚" * 30},
        {"role": "user", "content": "èƒ½å¦ä¼˜åŒ–ä¸€ä¸‹è¿™ä¸ªå‡½æ•°çš„æ€§èƒ½ï¼Ÿ" * 15},
        {"role": "assistant", "content": "å½“ç„¶å¯ä»¥ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ¨æ€è§„åˆ’æ¥ä¼˜åŒ–ã€‚" * 25},
        {"role": "user", "content": "å¤ªå¥½äº†ï¼Œèƒ½å¦å†è§£é‡Šä¸€ä¸‹æ—¶é—´å¤æ‚åº¦ï¼Ÿ" * 10},
        {"role": "assistant", "content": "æ—¶é—´å¤æ‚åº¦ä»O(2^n)ä¼˜åŒ–åˆ°äº†O(n)ã€‚" * 20},
        {"role": "user", "content": "éå¸¸æ„Ÿè°¢ä½ çš„è¯¦ç»†è§£é‡Šï¼"},  # æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
    ]
    return messages
def test_compression_strategy():
    """æµ‹è¯•å‹ç¼©ç­–ç•¥"""
    print("ğŸ”§ å¼€å§‹æµ‹è¯•æ™ºèƒ½å‹ç¼©ç­–ç•¥...")
    
    token_manager = TokenManager()
    model = "gpt-4"
    max_tokens = 1000  # è®¾ç½®è¾ƒå°çš„é™åˆ¶æ¥è§¦å‘å‹ç¼©
    
    # åˆ›å»ºæµ‹è¯•æ¶ˆæ¯
    test_messages = create_test_messages()
    print(f"ğŸ“ åˆ›å»ºäº† {len(test_messages)} æ¡æµ‹è¯•æ¶ˆæ¯")
    
    # è®¡ç®—åŸå§‹tokenæ•°é‡
    original_tokens = token_manager.count_message_tokens(test_messages, model)
    print(f"ğŸ“Š åŸå§‹æ¶ˆæ¯tokenæ•°é‡: {original_tokens}")
    
    if original_tokens <= max_tokens:
        print("âš ï¸  æ¶ˆæ¯æœªè¶…è¿‡é™åˆ¶ï¼Œå¢åŠ å†…å®¹...")
        # å¦‚æœæ²¡è¶…è¿‡é™åˆ¶ï¼Œå¢åŠ æ›´å¤šå†…å®¹
        for i in range(len(test_messages)):
            if test_messages[i]["role"] != "system":
                test_messages[i]["content"] = test_messages[i]["content"] * 5
        original_tokens = token_manager.count_message_tokens(test_messages, model)
        print(f"ğŸ“Š å¢åŠ å†…å®¹åtokenæ•°é‡: {original_tokens}")
    
    print(f"ğŸ¯ Tokené™åˆ¶: {max_tokens}")
    print(f"ğŸ“ˆ è¶…å‡ºæ¯”ä¾‹: {((original_tokens - max_tokens) / max_tokens * 100):.1f}%")
    
    # æµ‹è¯•åŸå§‹æˆªæ–­ç­–ç•¥
    print("\nğŸ”„ æµ‹è¯•åŸå§‹æˆªæ–­ç­–ç•¥...")
    truncated_messages = token_manager.truncate_messages(test_messages.copy(), max_tokens, model)
    truncated_tokens = token_manager.count_message_tokens(truncated_messages, model)
    print(f"âœ‚ï¸  åŸå§‹ç­–ç•¥ç»“æœ: {truncated_tokens} tokens, {len(truncated_messages)} æ¡æ¶ˆæ¯")
    
    # æµ‹è¯•æ™ºèƒ½å‹ç¼©ç­–ç•¥
    print("\nğŸ§  æµ‹è¯•æ™ºèƒ½å‹ç¼©ç­–ç•¥...")
    smart_messages = token_manager.truncate_messages_smart(test_messages.copy(), max_tokens, model)
    smart_tokens = token_manager.count_message_tokens(smart_messages, model)
    print(f"ğŸ¯ æ™ºèƒ½ç­–ç•¥ç»“æœ: {smart_tokens} tokens, {len(smart_messages)} æ¡æ¶ˆæ¯")
    
    # åˆ†æç»“æœ
    print("\nğŸ“‹ ç»“æœåˆ†æ:")
    print(f"åŸå§‹æ¶ˆæ¯: {original_tokens} tokens, {len(test_messages)} æ¡")
    print(f"åŸå§‹æˆªæ–­: {truncated_tokens} tokens, {len(truncated_messages)} æ¡")
    print(f"æ™ºèƒ½å‹ç¼©: {smart_tokens} tokens, {len(smart_messages)} æ¡")
    
    # éªŒè¯æœ€æ–°æ¶ˆæ¯æ˜¯å¦ä¿ç•™
    if smart_messages:
        last_message = smart_messages[-1]
        original_last = test_messages[-1]
        if last_message["content"] == original_last["content"]:
            print("âœ… æœ€æ–°ç”¨æˆ·æ¶ˆæ¯å®Œæ•´ä¿ç•™")
        else:
            print("âŒ æœ€æ–°ç”¨æˆ·æ¶ˆæ¯è¢«ä¿®æ”¹")
    
    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
    if smart_tokens <= max_tokens:
        print("âœ… æ™ºèƒ½å‹ç¼©ç­–ç•¥æˆåŠŸæ§åˆ¶åœ¨tokené™åˆ¶å†…")
    else:
        print(f"âŒ æ™ºèƒ½å‹ç¼©ç­–ç•¥ä»è¶…å‡ºé™åˆ¶: {smart_tokens} > {max_tokens}")
    
    return {
        'original': (original_tokens, len(test_messages)),
        'truncated': (truncated_tokens, len(truncated_messages)),
        'smart': (smart_tokens, len(smart_messages)),
        'success': smart_tokens <= max_tokens
    }
if __name__ == "__main__":
    try:
        result = test_compression_strategy()
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ! æ™ºèƒ½å‹ç¼©ç­–ç•¥{'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()